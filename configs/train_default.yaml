#---- CONFIG FOR GEOMETRIC VAE TRAINING ----- 

# ----- General args --------

# ---meta---
pretrain_exp_name: gvae_pretrain_default # must be different from expname
exp_name: gvae_default
pretrain: true
train: true
rgb_override: false # to train rgb nerfs, put this to true, and also the loss_rgb_override 
                    # in the training/pretraining args. All the other lossses must be set to False
# ----------

# data
dataset_name: shapenet_car_above
scenes_range_start: 0
n_scenes: 10 
rgb_img_size: 128

# vae
vae:
  pretrained_model_name_or_path: runwayml/stable-diffusion-v1-5
  revision: main
  normalization:
    img:
      window_length: 1000 
      actualize_window: true
      type: 'Tanh' #pick one of 'MinMax', 'Tanh', 'MuSigma', 'MuSigmaTanh'
      sigma_scale: 1 
      tanh_scale: 0.02 # use 0.1 and 'musigmatanh' by default
      groupby: 'channel' # pick 'channel' (normalize each channel independantly) or 'all'
      reduceto: 'point' # pick 'point' (average over the H and W dimensions) or 'tensor' (do not)
      decay: 'none' # pick 'none' or 'exp'. Whether to apply exponential decay in the computation of the mean and std
      decay_factor: 5 # the decay factor for the exponential decay
      eps: 1.e-4 # epsilon for numerical stability
      # bg_color: [0.503, 0.504, 0.5, 0.4957]  # for MuSigmaTanh w. scale 0.02
      # bg_color: [0.5085, 0.5103, 0.5000, 0.4893]  # for MuSigmaTanh w. scale 0.05
      # bg_color: [0.517, 0.520, 0.500, 0.478]  # for MuSigmaTanh w. scale 0.1
      # bg_color: [0.534, 0.54, 0.500, 0.4575]  # for MuSigmaTanh w. scale 0.2
      # bg_color: [0.567, 0.581, 0.502, 0.415]  # for MuSigmaTanh w. scale 0.4
      bg_color: [0.590, 0.568, 0.5027, 0.4462] # for tanh w. scale 0.02
      # bg_color: [0.713, 0.665, 0.506, 0.368] # for tanh w. scale 0.05
      # bg_color: [0.859, 0.795, 0.514, 0.255] # for tanh w. scale 0.1
      # bg_color: [0.969, 0.929, 0.5289, 0.111] # for tanh w. scale 0.2
      # bg_color: [0.994, 0.983, 0.559, 0.0279] # for tanh w. scale 0.4
      rgb_bg_color: [1., 1., 1.]

# evaluation
eval:
  video:
    n_scenes: 10 #number of different scenes to vizualize
    n_frames: 40
    fps: 10
    azimuth_range: [0, 1]
    elevation_range: [0.3, 0.3]
    radius_range: [1.3, 1.3]
  metrics:
    n_scenes: 10 #number of scenes to calculte the metrics upon
    log_scenes_independently: false
    #n_scenes_to_log: 10 #only if log_scenes_independently is set to true #TODO


rgb_nerf_as_latent_override: # is case RGB_OVERRRIDES is True
  n_channels: 3
  img_size: 128
  n_local_features: 32
  triplane_resolution: 64
  aggregation_mode: sum
  rendering_options:
    disparity_space_sampling: false
    clamp_mode: softplus
    depth_resolution: 48
    depth_resolution_importance: 48
    ray_start: 0.5
    ray_end: 2.1
    box_warp: 2
    bg_color: [1., 1., 1.]

# triplane  
latent_nerf: # local latent nerf
  mu_nerf: false # if true, we don't sample from the latent distrib but we use the mean
  concat_low_res_rgb: false # if true, we concatenate the low res rgb img to the latent img
  n_concat_channels: 3 # only relevant if concat_low_res_rgb is true
  n_latent_channels: 4
  img_size: 16
  n_local_features: 32
  triplane_resolution: 64
  aggregation_mode: sum
  rendering_options:
    disparity_space_sampling: false
    clamp_mode: softplus
    depth_resolution: 48
    depth_resolution_importance: 48
    ray_start: 0.5
    ray_end: 2.1
    box_warp: 2

global_latent_nerf:
  apply: false
  n_base: 25
  n_global_features: 22
  n_local_features: 10 # if apply is true, this overrides the n_local_features in the latent_nerf
  fusion_mode: concat # either 'concat' or 'sum'.
  bias: true

# pretraining
pretrain_args:
  losses: # encode nerf by default
    loss_alpha_d: False
    loss_ae: False
    loss_lnerf: True
    loss_low_res_rgb: False # True has effect only if concat_low_res_rgb is True
    loss_rgb_override: False # rgb override.

  freezes: # do not change
    freeze_decoder: True
    freeze_encoder: True
    freeze_lnerf: False
    freeze_global_lnerf: False
    freeze_base_coefs: False

  #optim
  warmup_window: true
  wandb_note: pretraining
  n_epochs: 5
  freeze_tinymlp_after_n_epoch : 90
  batch_size: 32

  cache_latents: 
    apply: true
    use_mean: true
    batch_size: 64

  scheduler: #TODO: add this per module
    type: 'multistep' #either 'exp' or 'multistep'
    exp_config:
      gamma: 0.988032
    multistep_config:
      milestones: [100, 200]
      gamma: 0.3

  encoder:
    lr: 1.e-4
  decoder:
    lr: 1.e-4
  latent_nerf:
    lr: 1.e-2
    tinymlp_lr: 1.e-2
  global_latent_nerf:
    lr: 1.e-2
  base_coefs:
    lr: 1.e-2
    
  lambda_ae: 0.1
  lambda_latent_nerf: 1
  lambda_alpha_D: 1
  lambda_low_res_rgb: 1
  lambda_rgb_override: 1
  lambda_kl: 0
  lambda_tv: 1.e-4
  tv_mode: 'l2' #either 'l2' or 'l1'
  lambda_depth_tv: 0
  depth_tv_mode: 'l2' #either 'l2' or 'l1'

  # logging
  log_sw_stats_every_iter: 10
  log_training_metrics_every_epoch: 1 
  eval_metrics_every_epoch: 1
  eval_video_every_epoch: 1
  save_every_epoch: 1
  save_latest_only : true

# training
train_args:
  losses:
    loss_alpha_d: True
    loss_ae: True
    loss_lnerf: True
    loss_low_res_rgb: False # True has effect only if concat_low_res_rgb is True
    loss_rgb_override: False # rgb override
    
  freezes: # (do not change)
    freeze_decoder: False
    freeze_encoder: False
    freeze_lnerf: False
    freeze_global_lnerf: False
    freeze_base_coefs: False
    
  #optim
  warmup_window: false
  wandb_note: training
  n_epochs: 5
  freeze_tinymlp_after_n_epoch : -1
  batch_size: 16

  cache_latents: 
    apply: false
    use_mean: true
    batch_size: 64

  scheduler: #TODO: add this per module
    type: 'multistep' #either 'exp' or 'multistep'
    exp_config:
      gamma: 0.988032
    multistep_config:
      milestones: [100, 200]
      gamma: 0.3

  encoder:
    lr: 1.e-4
  decoder:
    lr: 1.e-4
  latent_nerf:
    lr: 1.e-3
    tinymlp_lr: 1.e-3
  global_latent_nerf:
    lr: 1.e-2
  base_coefs:
    lr: 1.e-2

  lambda_ae: 0.1
  lambda_latent_nerf: 1
  lambda_alpha_D: 1
  lambda_low_res_rgb: 1
  lambda_rgb_override: 1
  lambda_kl: 0
  lambda_tv: 1.e-4
  tv_mode: 'l2' #either 'l2' or 'l1'
  lambda_depth_tv: 0
  depth_tv_mode: 'l2' #either 'l2' or 'l1'

  # logging
  log_sw_stats_every_iter: 10
  log_training_metrics_every_epoch: 1
  eval_metrics_every_epoch: 1
  eval_video_every_epoch: 1
  save_every_epoch: 1
  save_latest_only : true

# other
wandb_project_name: gvae
savedir: outputs